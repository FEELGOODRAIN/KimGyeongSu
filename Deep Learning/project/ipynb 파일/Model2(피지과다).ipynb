{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2439,"status":"ok","timestamp":1703060551103,"user":{"displayName":"김경수","userId":"10907451516248175311"},"user_tz":-540},"id":"0FGY4YR368Zm","outputId":"6f54bb05-744c-41fb-bfde-4a6d22fe5d2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxH6Jb4h7V0-"},"outputs":[],"source":["def rotate_image(x):\n","    return x.rotate(90)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4666,"status":"ok","timestamp":1703060555765,"user":{"displayName":"김경수","userId":"10907451516248175311"},"user_tz":-540},"id":"l7gpIgMR7X8H","outputId":"ef431a96-b15e-4dc9-d9dc-c2b9f524ff09"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.10/dist-packages (0.7.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n"]}],"source":["pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K-A4IhvT7jWH"},"outputs":[],"source":["import time\n","import datetime\n","import os\n","import copy\n","import cv2\n","import random\n","import numpy as np\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torch.optim import lr_scheduler\n","from torchvision import transforms, datasets\n","from torch.utils.data import Dataset,DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from efficientnet_pytorch import EfficientNet\n","from torchvision.transforms import InterpolationMode"]},{"cell_type":"code","source":["save_path = '/content/scalp_weights/'"],"metadata":{"id":"AXU_PJ5i7-Pp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def save_checkpoint(epoch, model, optimizer, acc):\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'accuracy': acc,\n","    }\n","    torch.save(checkpoint, save_path + 'checkpoint.pth')"],"metadata":{"id":"FQhs732z7u0i"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heqkhhXT7mRf","outputId":"4bffea71-09b6-4c0d-869e-e43396641807","executionInfo":{"status":"ok","timestamp":1703074031193,"user_tz":-540,"elapsed":13469982,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","300\n","Loaded pretrained weights for efficientnet-b3\n","batch_size : 32,  train/val : 56826 / 16236\n","['[원천]피지과다_0.양호', '[원천]피지과다_1.경증', '[원천]피지과다_2.중등도', '[원천]피지과다_3.중증']\n","에포크 0/99\n","----------\n","train Loss: 0.7308 Acc: 66.5435\n","val Loss: 0.8152 Acc: 64.5294\n","==> 최고 성능 모델 저장 - 0 / 64.5\n","에포크 0 소요 시간 24m 56s\n","\n","에포크 1/99\n","----------\n","train Loss: 0.6709 Acc: 69.3573\n","val Loss: 0.7857 Acc: 65.1762\n","==> 최고 성능 모델 저장 - 1 / 65.2\n","에포크 1 소요 시간 24m 56s\n","\n","에포크 2/99\n","----------\n","train Loss: 0.6547 Acc: 70.2812\n","val Loss: 0.7619 Acc: 65.1577\n","에포크 2 소요 시간 24m 57s\n","\n","에포크 3/99\n","----------\n","train Loss: 0.6391 Acc: 70.8549\n","val Loss: 0.7512 Acc: 66.3218\n","==> 최고 성능 모델 저장 - 3 / 66.3\n","에포크 3 소요 시간 24m 57s\n","\n","에포크 4/99\n","----------\n","train Loss: 0.6268 Acc: 71.4532\n","val Loss: 0.7687 Acc: 65.7058\n","에포크 4 소요 시간 24m 56s\n","\n","에포크 5/99\n","----------\n","train Loss: 0.6084 Acc: 72.3894\n","val Loss: 0.8082 Acc: 64.8066\n","에포크 5 소요 시간 24m 56s\n","\n","에포크 6/99\n","----------\n","train Loss: 0.5880 Acc: 73.2798\n","val Loss: 0.8355 Acc: 64.6465\n","에포크 6 소요 시간 24m 57s\n","\n","에포크 7/99\n","----------\n","train Loss: 0.5341 Acc: 75.9899\n","val Loss: 0.8368 Acc: 65.1207\n","에포크 7 소요 시간 24m 57s\n","\n","에포크 8/99\n","----------\n","train Loss: 0.5143 Acc: 76.9894\n","val Loss: 0.8477 Acc: 65.1146\n","에포크 8 소요 시간 24m 57s\n","\n","조기 종료: 연속된 5번의 에포크 동안 성능 개선 없음\n","학습 완료 소요 시간 224m 28s\n","최고 성능 Acc: 3 - 66.3\n","종료 시간 : 3:44:28\n"]},{"output_type":"execute_result","data":{"text/plain":["(EfficientNet(\n","   (_conv_stem): Conv2dStaticSamePadding(\n","     3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n","     (static_padding): ZeroPad2d((0, 1, 0, 1))\n","   )\n","   (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","   (_blocks): ModuleList(\n","     (0): MBConvBlock(\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         40, 10, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         10, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (1): MBConvBlock(\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         24, 6, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         6, 24, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (2): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n","         (static_padding): ZeroPad2d((0, 1, 0, 1))\n","       )\n","       (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         144, 6, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         6, 144, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (3-4): 2 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         192, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 192, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (5): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         192, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 192, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (6-7): 2 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         288, 12, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         12, 288, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (8): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n","         (static_padding): ZeroPad2d((0, 1, 0, 1))\n","       )\n","       (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         288, 12, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         12, 288, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (9-12): 4 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         576, 24, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         24, 576, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (13): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         576, 24, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         24, 576, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (14-17): 4 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         816, 34, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         34, 816, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (18): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         816, 34, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         34, 816, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (19-23): 5 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1392, 58, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         58, 1392, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (24): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1392, 58, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         58, 1392, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (25): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         2304, 96, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         96, 2304, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","   )\n","   (_conv_head): Conv2dStaticSamePadding(\n","     384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n","     (static_padding): Identity()\n","   )\n","   (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","   (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n","   (_dropout): Dropout(p=0.3, inplace=False)\n","   (_fc): Linear(in_features=1536, out_features=4, bias=True)\n","   (_swish): MemoryEfficientSwish()\n"," ),\n"," 3,\n"," 66.32175412663217,\n"," [0.7307735014435055,\n","  0.6709469068588678,\n","  0.6547100907712478,\n","  0.6390774108009807,\n","  0.626807729873084,\n","  0.6084023731309426,\n","  0.5879975403002993,\n","  0.5340663013553744,\n","  0.5143303248822968],\n"," [66.54348361665436,\n","  69.35733643050716,\n","  70.28120930559955,\n","  70.85489036708549,\n","  71.45320803857389,\n","  72.38939921866752,\n","  73.27983669447084,\n","  75.98986379474184,\n","  76.98940625769895],\n"," [0.8152039530213228,\n","  0.7856665356284322,\n","  0.7619090309046735,\n","  0.7512157415926647,\n","  0.7686765215672363,\n","  0.8082122001838261,\n","  0.83546492847265,\n","  0.8368447647508244,\n","  0.8477008699284131],\n"," [64.52944074895295,\n","  65.17615176151762,\n","  65.15767430401577,\n","  66.32175412663217,\n","  65.70583887657058,\n","  64.80660261148066,\n","  64.64646464646464,\n","  65.12071938901207,\n","  65.11456023651145])"]},"metadata":{},"execution_count":7}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","#배치 사이즈 조절\n","hyper_param_batch = 32\n","#랜덤성을 한가지로 맞추기 위해 시드 입력\n","random_seed = 100\n","random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","\n","num_classes = 4 # 분류할 클래스가 4개라는 뜻.\n","model_name = 'efficientnet-b3' # 모델명\n","# 폴더 경로 정하기\n","train_name = 'model2'\n","\n","PATH = '/content/scalp_weights/'\n","\n","data_train_path = '/content/gdrive/MyDrive/딥러닝/두피/피지과다 img/'\n","data_validation_path = '/content/gdrive/MyDrive/딥러닝/두피/피지과다 vail img/'\n","\n","image_size = EfficientNet.get_image_size(model_name)\n","print(image_size)\n","# 모델 이름은 Efficientnet , 클래스는 4개로 분류하는 모델 생성\n","model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n","model = model.to(device) # 모델을 GPU(없으면 cpu)에 적용\n","# 데이터의 증강 등 정제하는 과정\n","#interpolation :\n","# NEAREST(0)(얘가 제일 빠름) : 가장 가까운 이웃 픽셀의 값을 그대로 사용\n","# BOX(4) : 주변 픽셀의 가중평균을 사용\n","# BILINEAR(2) : 가까운 4개의 픽셀을 사용하여 선형 보간을 수행 , NEAREST보다 부드러움\n","# LANCZOS(1)(얘가 제일 느림) , BICUBIC(3)은 각각 BILINEAR의 기반이지만 , 더 정교하게 보간 , BILINEAR -> BICUBIC -> LANCZOS 순으로 느림\n","# HAMMING(5) : BOX와 유사하지만 , 얘가 더 정교하고 느림\n","# 가중 평균 : 주변 픽셀에 가중치를 곱해서 각각 더하고 , 줬던 가중치의 총합으로 나눠서 나오는 값이 가중평균\n","# 선형 보간 : 선으로 잇고 , 그 영역 안에서의 보간을 수행하는 것 ( 직선이면 직선상에서 )\n","transforms_train = transforms.Compose([\n","                                        transforms.Resize([int(image_size), int(image_size)], interpolation = InterpolationMode.BILINEAR),#크기 조절 , interpolation은 어떤 형식으로 보간할건지 정하는 것.\n","                                        transforms.RandomHorizontalFlip(p=0.5),\n","                                        transforms.RandomVerticalFlip(p=0.5),\n","                                        transforms.Lambda(lambda x: x.rotate(90)),\n","                                        transforms.RandomRotation(10),\n","                                        transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n","                                        transforms.ToTensor(), # tensor로 바꾸기\n","                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 정규화 , 수치는 ImageNet에서 널리 사용되는 수치\n","                                      ])\n","\n","transforms_val = transforms.Compose([\n","                                        transforms.Resize([int(image_size), int(image_size)], interpolation = InterpolationMode.BILINEAR),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","                                      ])\n","\n","\n","train_data_set = datasets.ImageFolder(data_train_path, transform=transforms_train) # data_train_path라는 폴더에서 이미지들을 가져와 위의 증강 과정을 거침\n","val_data_set = datasets.ImageFolder(data_validation_path, transform=transforms_val)\n","# dict 지정\n","dataloaders, batch_num = {}, {}\n","\n","dataloaders['train'] = DataLoader(train_data_set,\n","                                    batch_size=hyper_param_batch, # 몇개씩 배치할 것인지\n","                                    shuffle=True, # epoch마다 섞을 것인지\n","\n","                                    num_workers=4) # 크면 클수록 데이터를 빠르게 로드할 수 있지만 , 메모리 낭비가 심함\n","dataloaders['val'] = DataLoader(val_data_set,\n","                                    batch_size=hyper_param_batch,\n","                                    shuffle=False,\n","                                    num_workers=4)\n","\n","batch_num['train'], batch_num['val'] = len(train_data_set), len(val_data_set) # 학습할 데이터셋들의 크기 확인\n","\n","print('batch_size : %d,  train/val : %d / %d' % (hyper_param_batch, batch_num['train'], batch_num['val'])) # 최종적으로 학습할 데이터 규모 확인\n","\n","class_names = train_data_set.classes\n","print(class_names) # 사용될 4개의 클래스 확인\n","\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=5):\n","    start_time = time.time()\n","\n","    since = time.time()\n","    best_acc = 0.0\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n","\n","    consecutive_epochs_without_improvement = 0  # 연속 에포크 동안 개선이 없는 횟수를 세는 카운터\n","\n","    for epoch in range(num_epochs):\n","        print('에포크 {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        epoch_start = time.time()\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            num_cnt = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                num_cnt += len(labels)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = float(running_loss / num_cnt)\n","            epoch_acc = float((running_corrects.double() / num_cnt).cpu()*100)\n","\n","            if phase == 'train':\n","                train_loss.append(epoch_loss)\n","                train_acc.append(epoch_acc)\n","            else:\n","                val_loss.append(epoch_loss)\n","                val_acc.append(epoch_acc)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_idx = epoch\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","                # 세이브 포인트 저장\n","                save_checkpoint(epoch, model, optimizer, best_acc)\n","                consecutive_epochs_without_improvement = 0\n","                model.load_state_dict(best_model_wts)\n","                print('==> 최고 성능 모델 저장 - %d / %.1f'%(best_idx, best_acc))\n","            elif phase == 'val':\n","                consecutive_epochs_without_improvement += 1\n","\n","        epoch_end = time.time() - epoch_start\n","        print('에포크 {} 소요 시간 {:.0f}m {:.0f}s'.format(epoch, epoch_end // 60, epoch_end % 60))\n","        print()\n","\n","        if consecutive_epochs_without_improvement >= patience:\n","            print('조기 종료: 연속된 {}번의 에포크 동안 성능 개선 없음'.format(patience))\n","            break\n","\n","    time_elapsed = time.time() - since\n","    print('학습 완료 소요 시간 {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('최고 성능 Acc: %d - %.1f' %(best_idx, best_acc))\n","\n","    model.load_state_dict(best_model_wts)\n","\n","    torch.save(model, PATH + 'aram_'+train_name+'.pt')\n","    torch.save(model.state_dict(), PATH + 'president_aram_'+train_name+'.pt')\n","\n","\n","    end_sec = time.time() - start_time\n","    end_times = str(datetime.timedelta(seconds=end_sec)).split('.')\n","    end_time = end_times[0]\n","    print(\"종료 시간 :\", end_time)\n","\n","    return model, best_idx, best_acc, train_loss, train_acc, val_loss, val_acc\n","\n","\n","criterion = nn.CrossEntropyLoss() # 손실함수\n","\n","optimizer_ft = optim.Adam(model.parameters(),lr = 1e-4) # 모델 활성화함수를 Adam , 학습률은 1e - 4로 설정\n","exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) # step_size만큼의 에포크마다 학습률에 gamma를 곱해서 갱신, 0.001\n","\n","num_epochs = 100\n","train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)"]},{"cell_type":"code","source":["\"\"\"\n","function ConnectButton(){\n","    console.log(\"Connect pushed\");\n","    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n","}\n","setInterval(ConnectButton,60000);\n","\"\"\""],"metadata":{"id":"5r6TIPyq_5K1","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1703074031194,"user_tz":-540,"elapsed":20,"user":{"displayName":"김경수","userId":"10907451516248175311"}},"outputId":"4d4b3a3d-fcc8-4e89-e1ee-c3fce4d57d16"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nfunction ClickConnect(){\\nconsole.log(\"Working\");\\ndocument.querySelector(\"colab-toolbar-button#connect\").click()\\n}setInterval(ClickConnect, 1800000)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":[],"metadata":{"id":"0ptbT99ncHZq"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyP6BniyUE4qS3v3CphHxNnv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}