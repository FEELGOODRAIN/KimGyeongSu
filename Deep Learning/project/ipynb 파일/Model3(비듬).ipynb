{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3112,"status":"ok","timestamp":1703125642605,"user":{"displayName":"김경수","userId":"10907451516248175311"},"user_tz":-540},"id":"0FGY4YR368Zm","outputId":"73dab625-660f-4a55-8407-af1db95152d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"KxH6Jb4h7V0-","executionInfo":{"status":"ok","timestamp":1703142031459,"user_tz":-540,"elapsed":718,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"outputs":[],"source":["def rotate_image(x):\n","    return x.rotate(90)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5477,"status":"ok","timestamp":1703142036935,"user":{"displayName":"김경수","userId":"10907451516248175311"},"user_tz":-540},"id":"l7gpIgMR7X8H","outputId":"238725bb-435f-405e-b6a8-db51bfc1f40f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.10/dist-packages (0.7.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n"]}],"source":["pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"K-A4IhvT7jWH","executionInfo":{"status":"ok","timestamp":1703142042710,"user_tz":-540,"elapsed":5776,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"outputs":[],"source":["import time\n","import datetime\n","import os\n","import copy\n","import cv2\n","import random\n","import numpy as np\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torch.optim import lr_scheduler\n","from torchvision import transforms, datasets\n","from torch.utils.data import Dataset,DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from efficientnet_pytorch import EfficientNet\n","from torchvision.transforms import InterpolationMode"]},{"cell_type":"code","source":["save_path = '/content/scalp_weights/'"],"metadata":{"id":"AXU_PJ5i7-Pp","executionInfo":{"status":"ok","timestamp":1703142042710,"user_tz":-540,"elapsed":3,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def save_checkpoint(epoch, model, optimizer, acc):\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'accuracy': acc,\n","    }\n","    torch.save(checkpoint, save_path + 'checkpoint.pth')"],"metadata":{"id":"FQhs732z7u0i","executionInfo":{"status":"ok","timestamp":1703142042711,"user_tz":-540,"elapsed":4,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heqkhhXT7mRf","outputId":"f6613d51-b47f-4712-e2aa-e1e2cfd93ca8","executionInfo":{"status":"ok","timestamp":1703147407398,"user_tz":-540,"elapsed":5364691,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","600\n","Loaded pretrained weights for efficientnet-b7\n","batch_size : 32,  train/val : 28873 / 8248\n","['[원천]비듬_0.양호', '[원천]비듬_1', '[원천]비듬_2.중등도', '[원천]비듬_3.중증']\n","에포크 0/99\n","----------\n","train Loss: 0.1836 Acc: 92.7372\n","==> 최고 성능 모델 저장 - 0 / 92.7\n","val Loss: 1.0164 Acc: 73.5451\n","에포크 0 소요 시간 8m 10s\n","\n","에포크 1/99\n","----------\n","train Loss: 0.1455 Acc: 94.3754\n","==> 최고 성능 모델 저장 - 1 / 94.4\n","val Loss: 1.2969 Acc: 72.5388\n","에포크 1 소요 시간 8m 10s\n","\n","에포크 2/99\n","----------\n","train Loss: 0.1075 Acc: 96.0378\n","==> 최고 성능 모델 저장 - 2 / 96.0\n","val Loss: 1.6435 Acc: 71.2173\n","에포크 2 소요 시간 8m 8s\n","\n","에포크 3/99\n","----------\n","train Loss: 0.0791 Acc: 97.0388\n","==> 최고 성능 모델 저장 - 3 / 97.0\n","val Loss: 1.4194 Acc: 71.9690\n","에포크 3 소요 시간 8m 8s\n","\n","에포크 4/99\n","----------\n","train Loss: 0.0643 Acc: 97.5756\n","==> 최고 성능 모델 저장 - 4 / 97.6\n","val Loss: 1.3079 Acc: 73.5451\n","에포크 4 소요 시간 8m 8s\n","\n","에포크 5/99\n","----------\n","train Loss: 0.0555 Acc: 97.9877\n","==> 최고 성능 모델 저장 - 5 / 98.0\n","val Loss: 1.5923 Acc: 72.1508\n","에포크 5 소요 시간 8m 8s\n","\n","에포크 6/99\n","----------\n","train Loss: 0.0545 Acc: 97.9150\n","val Loss: 1.5433 Acc: 72.0902\n","에포크 6 소요 시간 8m 6s\n","\n","에포크 7/99\n","----------\n","train Loss: 0.1570 Acc: 94.1191\n","val Loss: 1.5265 Acc: 72.8055\n","에포크 7 소요 시간 8m 6s\n","\n","에포크 8/99\n","----------\n","train Loss: 0.1181 Acc: 95.6257\n","val Loss: 1.4636 Acc: 72.9389\n","에포크 8 소요 시간 8m 6s\n","\n","에포크 9/99\n","----------\n","train Loss: 0.0971 Acc: 96.4292\n","val Loss: 1.4907 Acc: 72.7692\n","에포크 9 소요 시간 8m 6s\n","\n","에포크 10/99\n","----------\n","train Loss: 0.0810 Acc: 97.1046\n","val Loss: 1.5250 Acc: 73.1935\n","에포크 10 소요 시간 8m 6s\n","\n","조기 종료: 연속된 5번의 에포크 동안 성능 개선 없음\n","학습 완료 소요 시간 89m 21s\n","최고 성능 Acc: 5 - 98.0\n","종료 시간 : 1:29:22\n"]},{"output_type":"execute_result","data":{"text/plain":["(EfficientNet(\n","   (_conv_stem): Conv2dStaticSamePadding(\n","     3, 64, kernel_size=(3, 3), stride=(2, 2), bias=False\n","     (static_padding): ZeroPad2d((0, 1, 0, 1))\n","   )\n","   (_bn0): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","   (_blocks): ModuleList(\n","     (0): MBConvBlock(\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         64, 64, kernel_size=(3, 3), stride=[1, 1], groups=64, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         64, 16, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         16, 64, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (1-3): 3 x MBConvBlock(\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         32, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 32, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (4): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         192, 192, kernel_size=(3, 3), stride=[2, 2], groups=192, bias=False\n","         (static_padding): ZeroPad2d((0, 1, 0, 1))\n","       )\n","       (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         192, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 192, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (5-10): 6 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         288, 12, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         12, 288, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (11): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         288, 288, kernel_size=(5, 5), stride=[2, 2], groups=288, bias=False\n","         (static_padding): ZeroPad2d((1, 2, 1, 2))\n","       )\n","       (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         288, 12, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         12, 288, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (12-17): 6 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         480, 20, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         20, 480, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (18): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         480, 480, kernel_size=(3, 3), stride=[2, 2], groups=480, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         480, 20, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         20, 480, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (19-27): 9 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (28): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(5, 5), stride=[1, 1], groups=960, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (29-37): 9 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1344, 56, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         56, 1344, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (38): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1344, 1344, kernel_size=(5, 5), stride=[2, 2], groups=1344, bias=False\n","         (static_padding): ZeroPad2d((1, 2, 1, 2))\n","       )\n","       (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1344, 56, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         56, 1344, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (39-50): 12 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         2304, 96, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         96, 2304, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (51): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         2304, 2304, kernel_size=(3, 3), stride=[1, 1], groups=2304, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         2304, 96, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         96, 2304, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (52-54): 3 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         3840, 160, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         160, 3840, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","   )\n","   (_conv_head): Conv2dStaticSamePadding(\n","     640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False\n","     (static_padding): Identity()\n","   )\n","   (_bn1): BatchNorm2d(2560, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","   (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n","   (_dropout): Dropout(p=0.5, inplace=False)\n","   (_fc): Linear(in_features=2560, out_features=4, bias=True)\n","   (_swish): MemoryEfficientSwish()\n"," ),\n"," 5,\n"," 97.98773941052194,\n"," [0.18358212398790336,\n","  0.14551626649501573,\n","  0.10751234795834333,\n","  0.07912601192949494,\n","  0.06434340239640383,\n","  0.05554810572267923,\n","  0.054535540471132335,\n","  0.15696800825448087,\n","  0.11809310232813067,\n","  0.09711645905924376,\n","  0.08100573879123793],\n"," [92.73715928375992,\n","  94.3753679908565,\n","  96.03782080144079,\n","  97.03875593114675,\n","  97.57558965123125,\n","  97.98773941052194,\n","  97.91500710005889,\n","  94.1190731825581,\n","  95.6256710421501,\n","  96.42918990059918,\n","  97.10456135489905],\n"," [1.0163879042742439,\n","  1.2969223430920411,\n","  1.6435413183590215,\n","  1.419445689662814,\n","  1.3079300837737629,\n","  1.5923273356303493,\n","  1.5433337209614357,\n","  1.5264794061522278,\n","  1.4636397083587114,\n","  1.490669222503438,\n","  1.525035992412892],\n"," [73.54510184287099,\n","  72.53879728419011,\n","  71.2172647914646,\n","  71.9689621726479,\n","  73.54510184287099,\n","  72.15082444228904,\n","  72.090203685742,\n","  72.8055286129971,\n","  72.93889427740058,\n","  72.76915615906887,\n","  73.19350145489815])"]},"metadata":{},"execution_count":6}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","#배치 사이즈 조절\n","hyper_param_batch = 32\n","#랜덤성을 한가지로 맞추기 위해 시드 입력\n","random_seed = 100\n","random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","\n","num_classes = 4 # 분류할 클래스가 4개라는 뜻.\n","model_name = 'efficientnet-b7' # 모델명\n","# 폴더 경로 정하기\n","train_name = 'model2'\n","\n","PATH = '/content/scalp_weights/'\n","\n","data_train_path = '/content/gdrive/MyDrive/딥러닝/두피/비듬 img/'\n","data_validation_path = '/content/gdrive/MyDrive/딥러닝/두피/비듬 vail img/'\n","\n","image_size = EfficientNet.get_image_size(model_name)\n","print(image_size)\n","# 모델 이름은 Efficientnet , 클래스는 4개로 분류하는 모델 생성\n","model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n","checkpoint = torch.load(PATH + 'checkpoint.pth')\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model = model.to(device) # 모델을 GPU(없으면 cpu)에 적용\n","# 데이터의 증강 등 정제하는 과정\n","#interpolation :\n","# NEAREST(0)(얘가 제일 빠름) : 가장 가까운 이웃 픽셀의 값을 그대로 사용\n","# BOX(4) : 주변 픽셀의 가중평균을 사용\n","# BILINEAR(2) : 가까운 4개의 픽셀을 사용하여 선형 보간을 수행 , NEAREST보다 부드러움\n","# LANCZOS(1)(얘가 제일 느림) , BICUBIC(3)은 각각 BILINEAR의 기반이지만 , 더 정교하게 보간 , BILINEAR -> BICUBIC -> LANCZOS 순으로 느림\n","# HAMMING(5) : BOX와 유사하지만 , 얘가 더 정교하고 느림\n","# 가중 평균 : 주변 픽셀에 가중치를 곱해서 각각 더하고 , 줬던 가중치의 총합으로 나눠서 나오는 값이 가중평균\n","# 선형 보간 : 선으로 잇고 , 그 영역 안에서의 보간을 수행하는 것 ( 직선이면 직선상에서 )\n","transforms_train = transforms.Compose([\n","                                        transforms.Resize([int(300), int(300)], interpolation = InterpolationMode.BILINEAR),#크기 조절 , interpolation은 어떤 형식으로 보간할건지 정하는 것.\n","                                        transforms.RandomHorizontalFlip(p=0.5),\n","                                        transforms.RandomVerticalFlip(p=0.5),\n","                                        transforms.Lambda(lambda x: x.rotate(90)),\n","                                        transforms.RandomRotation(10),\n","                                        transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n","                                        transforms.ToTensor(), # tensor로 바꾸기\n","                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 정규화 , 수치는 ImageNet에서 널리 사용되는 수치\n","                                      ])\n","\n","transforms_val = transforms.Compose([\n","                                        transforms.Resize([int(300), int(300)], interpolation = InterpolationMode.BILINEAR),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","                                      ])\n","\n","\n","train_data_set = datasets.ImageFolder(data_train_path, transform=transforms_train) # data_train_path라는 폴더에서 이미지들을 가져와 위의 증강 과정을 거침\n","val_data_set = datasets.ImageFolder(data_validation_path, transform=transforms_val)\n","# dict 지정\n","dataloaders, batch_num = {}, {}\n","\n","dataloaders['train'] = DataLoader(train_data_set,\n","                                    batch_size=hyper_param_batch, # 몇개씩 배치할 것인지\n","                                    shuffle=True, # epoch마다 섞을 것인지\n","\n","                                    num_workers=4) # 크면 클수록 데이터를 빠르게 로드할 수 있지만 , 메모리 낭비가 심함\n","dataloaders['val'] = DataLoader(val_data_set,\n","                                    batch_size=hyper_param_batch,\n","                                    shuffle=False,\n","                                    num_workers=4)\n","\n","batch_num['train'], batch_num['val'] = len(train_data_set), len(val_data_set) # 학습할 데이터셋들의 크기 확인\n","\n","print('batch_size : %d,  train/val : %d / %d' % (hyper_param_batch, batch_num['train'], batch_num['val'])) # 최종적으로 학습할 데이터 규모 확인\n","\n","class_names = train_data_set.classes\n","print(class_names) # 사용될 4개의 클래스 확인\n","\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=5):\n","    start_time = time.time()\n","\n","    since = time.time()\n","    best_acc = 0.0\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n","\n","    consecutive_epochs_without_improvement = 0  # 연속 에포크 동안 개선이 없는 횟수를 세는 카운터\n","\n","    for epoch in range(num_epochs):\n","        print('에포크 {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        epoch_start = time.time()\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            num_cnt = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                num_cnt += len(labels)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = float(running_loss / num_cnt)\n","            epoch_acc = float((running_corrects.double() / num_cnt).cpu()*100)\n","\n","            if phase == 'train':\n","                train_loss.append(epoch_loss)\n","                train_acc.append(epoch_acc)\n","            else:\n","                val_loss.append(epoch_loss)\n","                val_acc.append(epoch_acc)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            if phase == 'train' and epoch_acc > best_acc:\n","                best_idx = epoch\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","                # 세이브 포인트 저장\n","                save_checkpoint(epoch, model, optimizer, best_acc)\n","                consecutive_epochs_without_improvement = 0\n","                model.load_state_dict(best_model_wts)\n","                print('==> 최고 성능 모델 저장 - %d / %.1f'%(best_idx, best_acc))\n","            elif phase == 'train':\n","                consecutive_epochs_without_improvement += 1\n","\n","        epoch_end = time.time() - epoch_start\n","        print('에포크 {} 소요 시간 {:.0f}m {:.0f}s'.format(epoch, epoch_end // 60, epoch_end % 60))\n","        print()\n","\n","        if consecutive_epochs_without_improvement >= patience:\n","            print('조기 종료: 연속된 {}번의 에포크 동안 성능 개선 없음'.format(patience))\n","            break\n","\n","    time_elapsed = time.time() - since\n","    print('학습 완료 소요 시간 {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('최고 성능 Acc: %d - %.1f' %(best_idx, best_acc))\n","\n","    model.load_state_dict(best_model_wts)\n","\n","    torch.save(model, PATH + 'aram_'+train_name+'.pt')\n","    torch.save(model.state_dict(), PATH + 'president_aram_'+train_name+'.pt')\n","\n","\n","    end_sec = time.time() - start_time\n","    end_times = str(datetime.timedelta(seconds=end_sec)).split('.')\n","    end_time = end_times[0]\n","    print(\"종료 시간 :\", end_time)\n","\n","    return model, best_idx, best_acc, train_loss, train_acc, val_loss, val_acc\n","\n","\n","criterion = nn.CrossEntropyLoss() # 손실함수\n","\n","optimizer_ft = optim.Adam(model.parameters(),lr = 1e-4) # 모델 활성화함수를 Adam , 학습률은 1e - 4로 설정\n","exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) # step_size만큼의 에포크마다 학습률에 gamma를 곱해서 갱신, 0.001\n","\n","num_epochs = 100\n","train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)"]},{"cell_type":"code","source":["\"\"\"\n","function ConnectButton(){\n","    console.log(\"Connect pushed\");\n","    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click()\n","}\n","setInterval(ConnectButton,60000);\n","\"\"\""],"metadata":{"id":"5r6TIPyq_5K1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","\n","# 다운로드할 파일의 경로\n","file_path = '/content/scalp_weights/aram_model2.pt'\n","\n","# 파일 다운로드\n","files.download(file_path)"],"metadata":{"id":"0ptbT99ncHZq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","# 원하는 코드를 여기에 작성하세요\n","# 예: print(\"Hello, World!\")\n","\n","# 런타임 종료\n","os.kill(os.getpid(), 9)"],"metadata":{"id":"F2in8dpL6GI7"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyPH8JJ8rqmelZuSQmmv7vFF"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}