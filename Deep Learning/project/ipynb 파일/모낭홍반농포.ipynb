{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22922,"status":"ok","timestamp":1703296623631,"user":{"displayName":"김경수","userId":"10907451516248175311"},"user_tz":-540},"id":"lDxf9-rynIYp","outputId":"c8ba189b-0fa1-4bcf-bbc9-f76ae7750e7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"bQh6bKsOSDnf","executionInfo":{"status":"ok","timestamp":1703296623631,"user_tz":-540,"elapsed":4,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"outputs":[],"source":["def rotate_image(x):\n","    return x.rotate(90)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6732,"status":"ok","timestamp":1703296630360,"user":{"displayName":"김경수","userId":"10907451516248175311"},"user_tz":-540},"id":"7NUcvorTWCwe","outputId":"62657c94-c45f-4bb3-cc76-f0cb93059394"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting efficientnet_pytorch\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.1.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet_pytorch\n","  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=1f69e91e8759118fc5496afe52ef793377e2d86ee6698dc30ba95c9d0983b2a3\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","Successfully built efficientnet_pytorch\n","Installing collected packages: efficientnet_pytorch\n","Successfully installed efficientnet_pytorch-0.7.1\n"]}],"source":["pip install efficientnet_pytorch"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"zipBez9xV9J8","executionInfo":{"status":"ok","timestamp":1703296639332,"user_tz":-540,"elapsed":8976,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"outputs":[],"source":["import time\n","import datetime\n","import os\n","import copy\n","import cv2\n","import random\n","import numpy as np\n","import json\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torch.optim import lr_scheduler\n","from torchvision import transforms, datasets\n","from torch.utils.data import Dataset,DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from efficientnet_pytorch import EfficientNet\n","from torchvision.transforms import InterpolationMode\n"]},{"cell_type":"code","source":["save_path = '/content/scalp_weights/'"],"metadata":{"id":"8lvzJorBEdM3","executionInfo":{"status":"ok","timestamp":1703296639332,"user_tz":-540,"elapsed":4,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def save_checkpoint(epoch, model, optimizer, acc):\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'accuracy': acc,\n","    }\n","    torch.save(checkpoint, save_path + 'checkpoint.pth')"],"metadata":{"id":"M9cLg41EEfJx","executionInfo":{"status":"ok","timestamp":1703296639332,"user_tz":-540,"elapsed":3,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def save_checkpoint(epoch, model, optimizer, acc):\n","    checkpoint = {\n","        'epoch': epoch,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'accuracy': acc,\n","    }\n","    torch.save(model, save_path + 'model_checkpoint.pt')\n","    torch.save(checkpoint, save_path + 'checkpoint.pth')"],"metadata":{"id":"UIPz9jruAl8g","executionInfo":{"status":"ok","timestamp":1703296639332,"user_tz":-540,"elapsed":3,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4rewbNTVakJ","outputId":"3c8c2b5d-f9dd-4e51-ba95-13c26c63ca88","executionInfo":{"status":"ok","timestamp":1703298528881,"user_tz":-540,"elapsed":1888339,"user":{"displayName":"김경수","userId":"10907451516248175311"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n","600\n"]},{"output_type":"stream","name":"stderr","text":["Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b7-dcc49843.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b7-dcc49843.pth\n","100%|██████████| 254M/254M [00:00<00:00, 416MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded pretrained weights for efficientnet-b7\n","batch_size : 32,  train/val : 3750 / 1070\n","['[원천]모낭홍반농포_0.양호', '[원천]모낭홍반농포_1.경증', '[원천]모낭홍반농포_2.중등도', '[원천]모낭홍반농포_3.중증']\n","에포크 0/99\n","----------\n","train Loss: 0.9890 Acc: 60.0800\n","==> 최고 성능 모델 저장 - 0 / 60.1\n","val Loss: 0.6922 Acc: 71.5888\n","에포크 0 소요 시간 10m 13s\n","\n","에포크 1/99\n","----------\n","train Loss: 0.6637 Acc: 72.0800\n","==> 최고 성능 모델 저장 - 1 / 72.1\n","val Loss: 0.6588 Acc: 73.2710\n","에포크 1 소요 시간 1m 7s\n","\n","에포크 2/99\n","----------\n","train Loss: 0.5793 Acc: 76.7467\n","==> 최고 성능 모델 저장 - 2 / 76.7\n","val Loss: 0.6281 Acc: 73.2710\n","에포크 2 소요 시간 1m 7s\n","\n","에포크 3/99\n","----------\n","train Loss: 0.4862 Acc: 80.0533\n","==> 최고 성능 모델 저장 - 3 / 80.1\n","val Loss: 0.7467 Acc: 72.4299\n","에포크 3 소요 시간 1m 7s\n","\n","에포크 4/99\n","----------\n","train Loss: 0.4212 Acc: 82.8000\n","==> 최고 성능 모델 저장 - 4 / 82.8\n","val Loss: 0.7461 Acc: 72.2430\n","에포크 4 소요 시간 1m 8s\n","\n","에포크 5/99\n","----------\n","train Loss: 0.3347 Acc: 86.9067\n","==> 최고 성능 모델 저장 - 5 / 86.9\n","val Loss: 0.8005 Acc: 70.0935\n","에포크 5 소요 시간 1m 7s\n","\n","에포크 6/99\n","----------\n","train Loss: 0.2842 Acc: 88.9067\n","==> 최고 성능 모델 저장 - 6 / 88.9\n","val Loss: 0.8797 Acc: 70.2804\n","에포크 6 소요 시간 1m 7s\n","\n","에포크 7/99\n","----------\n","train Loss: 0.2084 Acc: 92.0267\n","==> 최고 성능 모델 저장 - 7 / 92.0\n","val Loss: 0.8074 Acc: 70.3738\n","에포크 7 소요 시간 1m 6s\n","\n","에포크 8/99\n","----------\n","train Loss: 0.1802 Acc: 94.3467\n","==> 최고 성능 모델 저장 - 8 / 94.3\n","val Loss: 0.8055 Acc: 71.3084\n","에포크 8 소요 시간 1m 7s\n","\n","에포크 9/99\n","----------\n","train Loss: 0.1675 Acc: 94.1600\n","val Loss: 0.8276 Acc: 71.3084\n","에포크 9 소요 시간 1m 4s\n","\n","에포크 10/99\n","----------\n","train Loss: 0.1488 Acc: 95.1467\n","==> 최고 성능 모델 저장 - 10 / 95.1\n","val Loss: 0.8376 Acc: 71.3084\n","에포크 10 소요 시간 1m 7s\n","\n","에포크 11/99\n","----------\n","train Loss: 0.1386 Acc: 94.9867\n","val Loss: 0.8466 Acc: 70.7477\n","에포크 11 소요 시간 1m 4s\n","\n","에포크 12/99\n","----------\n","train Loss: 0.1340 Acc: 95.6267\n","==> 최고 성능 모델 저장 - 12 / 95.6\n","val Loss: 0.8675 Acc: 71.1215\n","에포크 12 소요 시간 1m 7s\n","\n","에포크 13/99\n","----------\n","train Loss: 0.1358 Acc: 95.3600\n","val Loss: 0.8739 Acc: 70.2804\n","에포크 13 소요 시간 1m 4s\n","\n","에포크 14/99\n","----------\n","train Loss: 0.1091 Acc: 96.9333\n","==> 최고 성능 모델 저장 - 14 / 96.9\n","val Loss: 0.8849 Acc: 70.1869\n","에포크 14 소요 시간 1m 7s\n","\n","에포크 15/99\n","----------\n","train Loss: 0.1282 Acc: 95.8133\n","val Loss: 0.8805 Acc: 70.4673\n","에포크 15 소요 시간 1m 4s\n","\n","에포크 16/99\n","----------\n","train Loss: 0.1147 Acc: 96.1600\n","val Loss: 0.8795 Acc: 70.3738\n","에포크 16 소요 시간 1m 4s\n","\n","에포크 17/99\n","----------\n","train Loss: 0.1143 Acc: 96.1067\n","val Loss: 0.8855 Acc: 70.4673\n","에포크 17 소요 시간 1m 4s\n","\n","에포크 18/99\n","----------\n","train Loss: 0.1116 Acc: 96.3467\n","val Loss: 0.8857 Acc: 70.4673\n","에포크 18 소요 시간 1m 4s\n","\n","에포크 19/99\n","----------\n","train Loss: 0.1153 Acc: 96.2133\n","val Loss: 0.8889 Acc: 70.4673\n","에포크 19 소요 시간 1m 4s\n","\n","조기 종료: 연속된 5번의 에포크 동안 성능 개선 없음\n","학습 완료 소요 시간 31m 2s\n","최고 성능 Acc: 14 - 96.9\n","종료 시간 : 0:31:03\n"]},{"output_type":"execute_result","data":{"text/plain":["(EfficientNet(\n","   (_conv_stem): Conv2dStaticSamePadding(\n","     3, 64, kernel_size=(3, 3), stride=(2, 2), bias=False\n","     (static_padding): ZeroPad2d((0, 1, 0, 1))\n","   )\n","   (_bn0): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","   (_blocks): ModuleList(\n","     (0): MBConvBlock(\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         64, 64, kernel_size=(3, 3), stride=[1, 1], groups=64, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(64, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         64, 16, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         16, 64, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (1-3): 3 x MBConvBlock(\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         32, 32, kernel_size=(3, 3), stride=(1, 1), groups=32, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         32, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 32, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (4): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         192, 192, kernel_size=(3, 3), stride=[2, 2], groups=192, bias=False\n","         (static_padding): ZeroPad2d((0, 1, 0, 1))\n","       )\n","       (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         192, 8, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         8, 192, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (5-10): 6 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         288, 288, kernel_size=(3, 3), stride=(1, 1), groups=288, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         288, 12, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         12, 288, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (11): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         288, 288, kernel_size=(5, 5), stride=[2, 2], groups=288, bias=False\n","         (static_padding): ZeroPad2d((1, 2, 1, 2))\n","       )\n","       (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         288, 12, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         12, 288, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         288, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (12-17): 6 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         480, 480, kernel_size=(5, 5), stride=(1, 1), groups=480, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         480, 20, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         20, 480, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (18): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         480, 480, kernel_size=(3, 3), stride=[2, 2], groups=480, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         480, 20, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         20, 480, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         480, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (19-27): 9 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(3, 3), stride=(1, 1), groups=960, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (28): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         960, 960, kernel_size=(5, 5), stride=[1, 1], groups=960, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         960, 40, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         40, 960, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         960, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (29-37): 9 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1344, 1344, kernel_size=(5, 5), stride=(1, 1), groups=1344, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1344, 56, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         56, 1344, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(224, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (38): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         1344, 1344, kernel_size=(5, 5), stride=[2, 2], groups=1344, bias=False\n","         (static_padding): ZeroPad2d((1, 2, 1, 2))\n","       )\n","       (_bn1): BatchNorm2d(1344, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         1344, 56, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         56, 1344, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (39-50): 12 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         2304, 2304, kernel_size=(5, 5), stride=(1, 1), groups=2304, bias=False\n","         (static_padding): ZeroPad2d((2, 2, 2, 2))\n","       )\n","       (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         2304, 96, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         96, 2304, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (51): MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         2304, 2304, kernel_size=(3, 3), stride=[1, 1], groups=2304, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         2304, 96, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         96, 2304, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","     (52-54): 3 x MBConvBlock(\n","       (_expand_conv): Conv2dStaticSamePadding(\n","         640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn0): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_depthwise_conv): Conv2dStaticSamePadding(\n","         3840, 3840, kernel_size=(3, 3), stride=(1, 1), groups=3840, bias=False\n","         (static_padding): ZeroPad2d((1, 1, 1, 1))\n","       )\n","       (_bn1): BatchNorm2d(3840, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_se_reduce): Conv2dStaticSamePadding(\n","         3840, 160, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_se_expand): Conv2dStaticSamePadding(\n","         160, 3840, kernel_size=(1, 1), stride=(1, 1)\n","         (static_padding): Identity()\n","       )\n","       (_project_conv): Conv2dStaticSamePadding(\n","         3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False\n","         (static_padding): Identity()\n","       )\n","       (_bn2): BatchNorm2d(640, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","       (_swish): MemoryEfficientSwish()\n","     )\n","   )\n","   (_conv_head): Conv2dStaticSamePadding(\n","     640, 2560, kernel_size=(1, 1), stride=(1, 1), bias=False\n","     (static_padding): Identity()\n","   )\n","   (_bn1): BatchNorm2d(2560, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n","   (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n","   (_dropout): Dropout(p=0.5, inplace=False)\n","   (_fc): Linear(in_features=2560, out_features=4, bias=True)\n","   (_swish): MemoryEfficientSwish()\n"," ),\n"," 14,\n"," 96.93333333333334,\n"," [0.9889739005724589,\n","  0.6636950032552084,\n","  0.5793106506665547,\n","  0.48618610447247823,\n","  0.42123915087381997,\n","  0.3346732769648234,\n","  0.2841677923838298,\n","  0.20840352676709492,\n","  0.180159028840065,\n","  0.16752167040507,\n","  0.14882485904693604,\n","  0.13859676491419473,\n","  0.13399296895662943,\n","  0.13578832779725392,\n","  0.1091424961090088,\n","  0.12819192741711935,\n","  0.1147043929497401,\n","  0.11432326636314392,\n","  0.11160937714576721,\n","  0.11534230456352233],\n"," [60.08,\n","  72.08,\n","  76.74666666666667,\n","  80.05333333333333,\n","  82.80000000000001,\n","  86.90666666666667,\n","  88.90666666666667,\n","  92.02666666666667,\n","  94.34666666666666,\n","  94.16,\n","  95.14666666666668,\n","  94.98666666666668,\n","  95.62666666666667,\n","  95.36,\n","  96.93333333333334,\n","  95.81333333333333,\n","  96.16,\n","  96.10666666666667,\n","  96.34666666666666,\n","  96.21333333333334],\n"," [0.6922493312960473,\n","  0.6588108944001599,\n","  0.6281062475988798,\n","  0.7467164089746564,\n","  0.7461281610426501,\n","  0.8004772055928953,\n","  0.8796854491545775,\n","  0.8074144321067311,\n","  0.8054778082348476,\n","  0.827590508772948,\n","  0.8375779718996208,\n","  0.8466425735259725,\n","  0.8674510306287034,\n","  0.8738900437533298,\n","  0.884875606376434,\n","  0.880475089483172,\n","  0.8794850214619503,\n","  0.8854761169335552,\n","  0.8856646772857024,\n","  0.8889265375716664],\n"," [71.58878504672897,\n","  73.27102803738318,\n","  73.27102803738318,\n","  72.42990654205607,\n","  72.24299065420561,\n","  70.09345794392524,\n","  70.2803738317757,\n","  70.37383177570094,\n","  71.30841121495327,\n","  71.30841121495327,\n","  71.30841121495327,\n","  70.74766355140187,\n","  71.1214953271028,\n","  70.2803738317757,\n","  70.18691588785046,\n","  70.46728971962617,\n","  70.37383177570094,\n","  70.46728971962617,\n","  70.46728971962617,\n","  70.46728971962617])"]},"metadata":{},"execution_count":8}],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","#배치 사이즈 조절\n","hyper_param_batch = 32\n","#랜덤성을 한가지로 맞추기 위해 시드 입력\n","random_seed = 100\n","random.seed(random_seed)\n","torch.manual_seed(random_seed)\n","\n","num_classes = 4 # 분류할 클래스가 4개라는 뜻.\n","model_name = 'efficientnet-b7' # 모델명\n","# 폴더 경로 정하기\n","train_name = 'model2'\n","\n","PATH = '/content/scalp_weights/'\n","\n","data_train_path = '/content/gdrive/MyDrive/딥러닝/두피/모낭홍반농포 img/'\n","data_validation_path = '/content/gdrive/MyDrive/딥러닝/두피/모낭홍반농포 vail img/'\n","\n","image_size = EfficientNet.get_image_size(model_name)\n","print(image_size)\n","# 모델 이름은 Efficientnet , 클래스는 4개로 분류하는 모델 생성\n","model = EfficientNet.from_pretrained(model_name, num_classes=num_classes)\n","model = model.to(device) # 모델을 GPU(없으면 cpu)에 적용\n","# 데이터의 증강 등 정제하는 과정\n","#interpolation :\n","# NEAREST(0)(얘가 제일 빠름) : 가장 가까운 이웃 픽셀의 값을 그대로 사용\n","# BOX(4) : 주변 픽셀의 가중평균을 사용\n","# BILINEAR(2) : 가까운 4개의 픽셀을 사용하여 선형 보간을 수행 , NEAREST보다 부드러움\n","# LANCZOS(1)(얘가 제일 느림) , BICUBIC(3)은 각각 BILINEAR의 기반이지만 , 더 정교하게 보간 , BILINEAR -> BICUBIC -> LANCZOS 순으로 느림\n","# HAMMING(5) : BOX와 유사하지만 , 얘가 더 정교하고 느림\n","# 가중 평균 : 주변 픽셀에 가중치를 곱해서 각각 더하고 , 줬던 가중치의 총합으로 나눠서 나오는 값이 가중평균\n","# 선형 보간 : 선으로 잇고 , 그 영역 안에서의 보간을 수행하는 것 ( 직선이면 직선상에서 )\n","transforms_train = transforms.Compose([\n","                                        transforms.Resize([int(300), int(300)], interpolation = InterpolationMode.BILINEAR),#크기 조절 , interpolation은 어떤 형식으로 보간할건지 정하는 것.\n","                                        transforms.RandomHorizontalFlip(p=0.5),\n","                                        transforms.RandomVerticalFlip(p=0.5),\n","                                        transforms.Lambda(lambda x: x.rotate(90)),\n","                                        transforms.RandomRotation(10),\n","                                        transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n","                                        transforms.ToTensor(), # tensor로 바꾸기\n","                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 정규화 , 수치는 ImageNet에서 널리 사용되는 수치\n","                                      ])\n","\n","transforms_val = transforms.Compose([\n","                                        transforms.Resize([int(300), int(300)], interpolation = InterpolationMode.BILINEAR),\n","                                        transforms.ToTensor(),\n","                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","                                      ])\n","\n","\n","train_data_set = datasets.ImageFolder(data_train_path, transform=transforms_train) # data_train_path라는 폴더에서 이미지들을 가져와 위의 증강 과정을 거침\n","val_data_set = datasets.ImageFolder(data_validation_path, transform=transforms_val)\n","# dict 지정\n","dataloaders, batch_num = {}, {}\n","\n","dataloaders['train'] = DataLoader(train_data_set,\n","                                    batch_size=hyper_param_batch, # 몇개씩 배치할 것인지\n","                                    shuffle=True, # epoch마다 섞을 것인지\n","\n","                                    num_workers=4) # 크면 클수록 데이터를 빠르게 로드할 수 있지만 , 메모리 낭비가 심함\n","dataloaders['val'] = DataLoader(val_data_set,\n","                                    batch_size=hyper_param_batch,\n","                                    shuffle=False,\n","                                    num_workers=4)\n","\n","batch_num['train'], batch_num['val'] = len(train_data_set), len(val_data_set) # 학습할 데이터셋들의 크기 확인\n","\n","print('batch_size : %d,  train/val : %d / %d' % (hyper_param_batch, batch_num['train'], batch_num['val'])) # 최종적으로 학습할 데이터 규모 확인\n","\n","class_names = train_data_set.classes\n","print(class_names) # 사용될 4개의 클래스 확인\n","\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25, patience=5):\n","    start_time = time.time()\n","\n","    since = time.time()\n","    best_acc = 0.0\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n","\n","    consecutive_epochs_without_improvement = 0  # 연속 에포크 동안 개선이 없는 횟수를 세는 카운터\n","\n","    for epoch in range(num_epochs):\n","        print('에포크 {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        epoch_start = time.time()\n","\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","            num_cnt = 0\n","\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","                num_cnt += len(labels)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = float(running_loss / num_cnt)\n","            epoch_acc = float((running_corrects.double() / num_cnt).cpu()*100)\n","\n","            if phase == 'train':\n","                train_loss.append(epoch_loss)\n","                train_acc.append(epoch_acc)\n","            else:\n","                val_loss.append(epoch_loss)\n","                val_acc.append(epoch_acc)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            if phase == 'train' and epoch_acc > best_acc:\n","                best_idx = epoch\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","                # 세이브 포인트 저장\n","                save_checkpoint(epoch, model, optimizer, best_acc)\n","                consecutive_epochs_without_improvement = 0\n","                model.load_state_dict(best_model_wts)\n","                print('==> 최고 성능 모델 저장 - %d / %.1f'%(best_idx, best_acc))\n","            elif phase == 'train':\n","                consecutive_epochs_without_improvement += 1\n","\n","        epoch_end = time.time() - epoch_start\n","        print('에포크 {} 소요 시간 {:.0f}m {:.0f}s'.format(epoch, epoch_end // 60, epoch_end % 60))\n","        print()\n","\n","        if consecutive_epochs_without_improvement >= patience:\n","            print('조기 종료: 연속된 {}번의 에포크 동안 성능 개선 없음'.format(patience))\n","            break\n","\n","    time_elapsed = time.time() - since\n","    print('학습 완료 소요 시간 {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('최고 성능 Acc: %d - %.1f' %(best_idx, best_acc))\n","\n","    model.load_state_dict(best_model_wts)\n","\n","    torch.save(model, PATH + 'aram_'+train_name+'.pt')\n","    torch.save(model.state_dict(), PATH + 'president_aram_'+train_name+'.pt')\n","\n","\n","    end_sec = time.time() - start_time\n","    end_times = str(datetime.timedelta(seconds=end_sec)).split('.')\n","    end_time = end_times[0]\n","    print(\"종료 시간 :\", end_time)\n","\n","    return model, best_idx, best_acc, train_loss, train_acc, val_loss, val_acc\n","\n","\n","criterion = nn.CrossEntropyLoss() # 손실함수\n","\n","optimizer_ft = optim.Adam(model.parameters(),lr = 1e-4) # 모델 활성화함수를 Adam , 학습률은 1e - 4로 설정\n","exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1) # step_size만큼의 에포크마다 학습률에 gamma를 곱해서 갱신, 0.001\n","\n","num_epochs = 100\n","train_model(model, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=num_epochs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iT01OUaQWIml"},"outputs":[],"source":["from google.colab import files\n","\n","# 저장된 모델 파일 다운로드\n","files.download('/content/scalp_weights/aram_model1.pt')"]},{"cell_type":"code","source":[],"metadata":{"id":"PsENQcXilea7"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyPKMJIaIke26jqAz7jBB5oa"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}